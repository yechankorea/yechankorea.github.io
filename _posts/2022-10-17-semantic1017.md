---
layout: single
title: "시멘틱 관련 링크"
---


### 
[Multi-Task DNN](https://gaussian37.github.io/dl-concept-mtl/) (JINSOL KIM)

[autoencoder](https://excelsior-cjh.tistory.com/m/187) (AE,VAE,Sparse AE)

차원 축소기법 에 대해 생각 해봐야할듯.
기존 기법들 PCA

pruning 기법에 대해 생각해보자.
[pruning 소개](https://velog.io/@woojinn8/LightWeight-Deep-Learning-1.-Pruning)
모델 경량화..?
iot 에 쓸 수 있지 않을까 (파라미터가 반토막 난다면 러닝타임도 반토막 나나?/ 아마 아닐것 같다)
pruning

----







딥러닝 모델 압축 Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding (ICLR 2016 Oral)

baseline으로 많이 나옴 .

 

-- 20221104 (금)--
VAE  > GAN > Diffusion
GNN 

간단한 거 부터 구현해보자. 

------20221122(화)-------
- SEMANTIC COMMUNICATION
- 비트 단위가 아닌 의미 단위의 통신.
- 의미가 정확히 어떤 것인지 모르겠지만, 수신단에서 TASK를 성공적으로 수행한다면. 의미가 통했다 라고 볼 수 있을 것 같다.
- TASK-ORIENTED COMMUNICATION
- 같은 원천 정보를 보더라도, 하고자 하는 TASK에 따라서, 의미 정보가 달라질 것이다. (가정)
- 의미 정보를 봐서, 이 정보가 어떤 TASK를 목적으로 압축된 의미정보인지 파알 할 수 있다면?
- 기존에 TASK-ORIENTED COMMUNICATION에서는 어떠한 의미 정보를 보낼 때, 어떤 TASK를 위한 의미 정보인지 LABELING 하는 resource를 할당할 것이다.
- 의미 정보를 봐서, 어떤 task에 적합한 의미정보인지 특정할 수 있다면, 여기서 성능 이득이 존재할 것이다.
- 해야될 것은? 
- 의미 정보(여러 차원들이 dependent 한 정보로 형성이 될 텐데)
- 어떤 상호 관계가 있는 데이터들을 집어넣어서, classification 하는 문제?
- GNN을 이용해 볼 까?
- 수학적 분석으로 의미 정보들의 확률 분포를 파악해서 KL DIVERGENCE 를 이용하면 어떨까?






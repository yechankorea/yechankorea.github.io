---
layout: single
title: "semantic0919"
---
# [논문 리뷰] Task-Oriented Semantic Communication with Semantic Reconstruction: An Extended Rate-Distortion Theory Based Scheme



## Abstract

엣지 추론을 위한 task-oriented communication.

로컬데이터에서 feature vector를 뽑아내 low-end edge device 에서 powerful edge 서버로 전송할 때.

데이터를 **informative 하고 compact한 표현**으로 encoding 하는 것은 중요하다.(low latency, limited bandwidth 때문에)

본 논문에서는 learning based communication scheme(task-oriented 수단으로 feature extraction,source coding, channel coding을 joint 하게 설계하는)을 제안한다. 다시 말하면, **data reconstruction보다 downstream inference task를  타겟**하겠다는 것이다.( 복원하는 것이 목표가 아닌 task에 적합한 inference 하는 것이 목표.)

또한, IB(information bottleneck) framework를 활용해서 **rate-distortion trade-off(informativeness of the encoded feature과 inference performance)**를 공식화한다.( 인코딩된 feautre의 정보성과 vs 추론 성능)

information bottleneck optimization은 고차원에서 계산이 힘드므로, 다루기 쉬운 **upper bound를 만들기 위해 VIB(variational information bottleneck**,변동 정보병목현상)을 채택한다.  또한 통신 오버헤드를 줄이기 위해 **sparsity-inducing distribution(희소성 유도 분포)을 VIB framwork의 변형으로 활용**하여 **encoded feature vecotr를 희소화** 한다. 

또한 실제 통신시스템의 dynamic 채널 조건을 고려하기 위해,

 encoded된 feature의 activated 차원을 다른 채널 조건에 적응적으로 조정하기 위해서,  dynamic neural net기반으로 하는 **variable length feature encoding scheme**을 제안한다.

제안된 task-oriented comm이 기존 기법보다 더 나은 rate-distortion tradeoff를 달성하고, 다이나믹 채널 조건에서 low latency를 보인다.

## I. INTRODUCTION

edge-inference 에서 latency 중요하다. 이는 information bottleneck problem을 유발한다.

이를 해결하기 위해 기존 기법들은 device-edge co-inference 방법을 사용해왔다.

해당 기법은 DNN을 장치와 서버에 배치하기 위해 두개의 하위 네트워크로 분할하여, feature compression과 transmission을 전통적인 통신 모듈로 남겨 놓았다. 이러한 종류의 분리 처리는 무선통신과 추론 작업간의 상호 작용을 무시하기에, 협업 추론의 완전한 이점을 활용하지 못한다(특정 task에 적응할 수 있기 때문에).

해당 한계를 극복하기 위해, 본 논문에서는 edge inference와 IB framework내에서의 innovative learning-driven approach를 제안하기위해, task-oriented communication를 제안한다.

### A. Related Works and Motivations

기존에는 data-oriented communication에 집중 했었다. 우리는 **downstream task를 위한 최소한이지만 원하는 task를 수행하기에 충분한 정보를 전송**하기 위한 task-oriented communication으로 설계할 것이다.

task를 잘 수행하기 위한 방법으로 **cross-entropy**로 training 할 것이다.(classification)

task-oriented를 위한 E2E learning-driven 구조는 한계점이 있다.

	- 인코딩된 feature vector의 정보량과, 테스크 추론을 위한 효과를 정량화 할 수 없다.(이는 더 높은 추론 성능 발휘를 방해한다.)
	- 다이나믹한 채널 조건은 신뢰할 수 있는 feature transmission의 adaptive한 encoding을 필요로 한다.

​	-> 이 부분에 대한 방법은 이 논문의 main motivation이 될 것이다.

기존에 data-oriented communication은 source&channel coding 이론에 의존했다. 이는 task-oriented comm에 optimal이 아니다.

Information bottleneck 이 등장했다 

![image-20220926032111604](../images/2022-09-22-semantic02/image-20220926032111604.png)

Information bottleneck

balance between **'data fit' & 'generalization'** by using MI (cost function과 regularizer로써)

maximizes :MI (between latency representation & label of the data) -> promote accuracy

minimized : MI(representation & input sample) -> promote generalization 

> *(압축 관련아닌가? 왜 generalization이라 했지?)*

이러한 trade off(relevant information의 보존 & compact한 representation 찾기)는 band-limited한 edge inference에 적합하며, 본 논문의 모델 구조의 메인 디자인 원리가 될 것이다.

### B. Contributions

본 논문에서는 IB 원리에 기반하여 device-edge co-inference기법에서 task-oriented communication을 하기위한 효율적인 방법을 제시할 것이다.

1. 앞서 얘기한 IB framework 이용해서 rate-distortion 이론을 formalizing 할 것이다. wireless edge inference에서 IB가 고려된 첫 번째 논문이다. 
2. IB formulation에 있는 mutual information은 고차원에서 DNN으로 다루기 힘들다. 그래서 **VIB(variational information bottleneck)이라는 variational approximation을 사용할 것**이다. 이를 이용해 MI를 다루기 쉬운 **MI의 upper bound**로 approximation 할 것이다. 게다가 **sparsity-inducing distribution이라는 사전 변형을 이용**함으로써, VIB framework는 **불필요한 encoded feature의 차원을 식별하고 다듬어** 통신의 오버헤드를 줄일 것이다. 이러한 방법을 **VFE(variational feature encoding)**이라 한다.
3. 다이나믹한 채널 컨디션에 따라 가변 길이의 VFE, 즉 **VL-VFE(variable-length variational feature encoding)을 사용할 것**이다.**(채널 컨디션에 따라서 active한 차원을 조절가능**하게 할 수 있는 다이나믹 뉴럴넷으로 구성되어 있다.)
4. image classification이라는 task에서 static&dynamic 채널 컨디션에서 검증할 것이다. 기존 기법들보다 높은 성능을 보였다.

## II. SYSTEM MODEL AND PROBLEM DESCRIPTION

### A. System Model

![image-20220926034700764](../images/2022-09-22-semantic02/image-20220926034700764.png)

![image-20220926035354284](../images/2022-09-22-semantic02/image-20220926035354284.png)

![image-20220926035401355](../images/2022-09-22-semantic02/image-20220926035401355.png)

앞단 파라미터 $\phi$  (feature extractor and a JSCC encoder) - on devised net

뒷단 파라미터 $\theta$ (inference) -server based net

scalar Gaussian channel 가정![image-20220926035813218](../images/2022-09-22-semantic02/image-20220926035813218.png)![image-20220926035821190](../images/2022-09-22-semantic02/image-20220926035821190.png)

z(feature vector)의 각 차원마다 power constraint함.(![image-20220926035734058](../images/2022-09-22-semantic02/image-20220926035734058.png),n은 encoded feature vector의 차원)

### B. Problem Description

앞서 얘기한데로, 심볼을 더많은 차원을 이용해 보내게 된다면 높은 퀄리티의 feature vector를 갖게 되고, 높은 accuracy를 얻게 되지만, 오버헤드와 latency가 증가하게 된다. 따라서 inference performance와 overhead의 trade-off를 자연스레 가지게 된다. 이것은 새롭고 특별한 버전의 rate-distortion trade-off 로 볼 수 있다. 그러므로 optimization problem을 공식하기 위해, 우리는 IB원리에 의존하며 다음과 같은 objective function을 최소화 해야한다.

![image-20220926040544403](../images/2022-09-22-semantic02/image-20220926040544403.png)

위의 IB objective function은 파리미터$\theta$ 와 unrelated 되어있다. 왜냐하면  ![image-20220926040752887](../images/2022-09-22-semantic02/image-20220926040752887.png)이기 때문이다. 직관적으로 생각해봐도 알 수 있다.

그리고 H(Y)는 input data distribution에 관계된 상수항이다. 따라서 objective function에서 무시가능 하다.

Distortion에 해당하는 $I(\hat{Z},Y)$항은$X$가 주어졌을 때 $\hat{Z}$에서의 (최소한의 차원으로) 보존된 정보량임을 알 수 있다.

$-I(\hat{Z},Y)$는  $-H(Y)+H(Y\mid\hat{Z})$ 으로 나타낼 수 있고 H(Y)는 상수이므로, $H(Y\mid\hat{Z})$를 최소화 하면 된다. 이는 Z^이 주어졌을 때, Y의 불확실성(distortion)을 최소화 한다고 생각할 수 있다.

그러므로 IB principle은 rate-distortion tradeoff를 형식화 한다고 할 수 있으며, conditional mutual information인 ![image-20220926042344916](../images/2022-09-22-semantic02/image-20220926042344916.png)(Y가 주어졌을 때 Z^과 X의 mutual information)를 최소화 한다. ![image-20220926042508752](../images/2022-09-22-semantic02/image-20220926042508752.png)는 전송하고자하는 redundant한 정보의 양과 대응된다(얼마나 압축되냐의 관계이지). 

data-oriented communication과 비교해 봤을 때, IB framework는 최대한  task-relevant information을 유지하고, H(X)보다 작은 ![image-20220926042630075](../images/2022-09-22-semantic02/image-20220926042630075.png)을 발생시켜서 통신 오버헤드를 줄인다.

### C. Main Challenges

1. MI 측정방법 : 정확한 확률 분포를 모르는 고차원에서 MI 측정은 매우 어렵다.(왜냐하면 확률 분포의 경험적 추정(empirical estimate)에서는 표본 수가 차원에 따라 기하급수적으로 증가하기 때문에) 그래서 tractable한 MI estimator는 중요한 요소이다.
2. 통신 오버헤드의 효과적인 컨트롤 : input data & feature vector 간의 MI를 최소화하는 것은 task와 상관없는 정보에 관한 redundancy를 줄이는 것이다.(압축) 그러나 redundancy reduction과 feature sparsification(feature 희소화, JSCC로 통신 오버헤드를 제어하는)간의 직접적인 연결은 없다. 그러므로 통신 오버헤드를 줄이기 위한 효과적인 방법으로, 전송할 심볼 수를 최소화 하기위해 방해물(nuisance)들을 확장가능한 차원으로 집계(aggregate)하는 방법이 있다.
3. 다이나믹한 채널 컨디션 :  DNN기반에서는 encoded feature length를 조절하는 것은 쉽지 않다. 보통 하이퍼 파라미터로 정해져 있기 때문이다. 채널 조건에 따라 뉴런의 활성화를 변경하기 위해서 새로운 모듈을 제시한다.

## III. VARIATIONAL FEATURE ENCODING





